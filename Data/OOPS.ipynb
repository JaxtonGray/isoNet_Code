{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I F'd up\n",
    "================\n",
    "I made a mistake in the hydroGFD extraction. And I need to try again but starting from the beginning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import glob\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNIP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>O18(1)</th>\n",
       "      <th>O18(2)</th>\n",
       "      <th>O18Avg</th>\n",
       "      <th>H2(1)</th>\n",
       "      <th>H2(2)</th>\n",
       "      <th>H2avg</th>\n",
       "      <th>dex</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Prec(1)</th>\n",
       "      <th>Prec(2)</th>\n",
       "      <th>Prec(3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-02-02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-50.700</td>\n",
       "      <td>33.460</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>84.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-03-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-48.040</td>\n",
       "      <td>20.800</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>164.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-04-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-27.485</td>\n",
       "      <td>59.555</td>\n",
       "      <td>1.7</td>\n",
       "      <td>95.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-05-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-50.455</td>\n",
       "      <td>9.945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-06-02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-76.480</td>\n",
       "      <td>-29.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-03-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-04-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-06-02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-07-02</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3270 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Station    Lat   Long    Alt       Date  Month O18(1) O18(2)  O18Avg  \\\n",
       "0        BAB  47.98 -55.82  190.0 1997-02-02    2.0    NaN    NaN -10.520   \n",
       "1        BAB  47.98 -55.82  190.0 1997-03-02    3.0    NaN    NaN  -8.605   \n",
       "2        BAB  47.98 -55.82  190.0 1997-04-02    4.0    NaN    NaN -10.880   \n",
       "3        BAB  47.98 -55.82  190.0 1997-05-02    5.0    NaN    NaN  -7.550   \n",
       "4        BAB  47.98 -55.82  190.0 1997-06-02    6.0    NaN    NaN  -5.835   \n",
       "...      ...    ...    ...    ...        ...    ...    ...    ...     ...   \n",
       "3265     HAL  68.47 -81.15    8.0 2007-03-02    3.0    NaN    NaN     NaN   \n",
       "3266     HAL  68.47 -81.15    8.0 2007-04-02    4.0    NaN    NaN     NaN   \n",
       "3267     HAL  68.47 -81.15    8.0 2007-05-02    5.0    NaN    NaN     NaN   \n",
       "3268     HAL  68.47 -81.15    8.0 2007-06-02    6.0    NaN    NaN     NaN   \n",
       "3269     HAL  68.47 -81.15    8.0 2007-07-02    7.0    NaN    NaN     NaN   \n",
       "\n",
       "     H2(1)  H2(2)   H2avg     dex  Temp  Prec(1)  Prec(2) Prec(3)  \n",
       "0      NaN    NaN -50.700  33.460  -8.2     84.5      NaN     8.1  \n",
       "1      NaN    NaN -48.040  20.800  -6.4    164.6      NaN    12.1  \n",
       "2      NaN    NaN -27.485  59.555   1.7     95.4      NaN     9.0  \n",
       "3      NaN    NaN -50.455   9.945   NaN      NaN      NaN    12.4  \n",
       "4      NaN    NaN -76.480 -29.800   NaN      NaN      NaN     9.2  \n",
       "...    ...    ...     ...     ...   ...      ...      ...     ...  \n",
       "3265   NaN    NaN     NaN     NaN   NaN      NaN      NaN     NaN  \n",
       "3266   NaN    NaN     NaN     NaN   NaN      NaN      NaN     NaN  \n",
       "3267   NaN    NaN     NaN     NaN   NaN      NaN      NaN     NaN  \n",
       "3268   NaN    NaN     NaN     NaN   NaN      NaN      NaN     NaN  \n",
       "3269   NaN    NaN     NaN     NaN   NaN      NaN      NaN     NaN  \n",
       "\n",
       "[3270 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the stations within the CNIP dataset to extract\n",
    "stationList = [\"BAB\", \"BON\", \"CPA\", \"EGB\", \"ELA\", \"EST\", \"GOB\", \"HAB\", \"SAT\", \"SNA\", \"SKT\", \"OTT\", \"BRA\", \"CAM\", \"EUR\", \"RES\", \"ALR\", \"HAL\"]\n",
    "cnipDict = {} # Dictionary to store the CNIP data\n",
    "stationCoords = {} # Dict to store the station coordinates\n",
    "# Loop through each station and extract the data\n",
    "for station in stationList:\n",
    "    # Read in the data\n",
    "    data = pd.read_excel(\"CNIP Updated Data Stations 10.08.2009..xls\", header=None, sheet_name=station, skiprows=[0, 1])\n",
    "\n",
    "    #Making sure the columns are filled properly with constant values: Station, Lat, Long, Alt\n",
    "    data[0] = station #Station\n",
    "    data[1] = data[1].iloc[0] #Lat\n",
    "    data[2] = data[2].iloc[0] *-1 #Long\n",
    "    data[3] = data[3].iloc[0] #Alt\n",
    "    stationCoords[station] = tuple([data[1].iloc[0], data[2].iloc[0]]) #Store the station coordinates\n",
    "    #Add the station data to the dictionary\n",
    "    cnipDict[station] = data\n",
    "\n",
    "columns = [\"Station\", \"Lat\", \"Long\", \"Alt\", \"Date\", \"Month\", \"O18(1)\", \"O18(2)\", \"O18Avg\", \"H2(1)\", \"H2(2)\", \"H2avg\", \"dex\", \"Temp\", \"Prec(1)\", \"Prec(2)\", \"Prec(3)\"]\n",
    "# Combine the CNIP data into one dataframe\n",
    "cnip = pd.concat(cnipDict.values(), ignore_index=True)\n",
    "cnip.columns = columns\n",
    "\n",
    "# Print the CNIP dataframe\n",
    "cnip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Station</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Date</th>\n",
       "      <th>O18Avg</th>\n",
       "      <th>H2avg</th>\n",
       "      <th>dex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-02-02</td>\n",
       "      <td>-10.520</td>\n",
       "      <td>-50.700</td>\n",
       "      <td>33.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-03-02</td>\n",
       "      <td>-8.605</td>\n",
       "      <td>-48.040</td>\n",
       "      <td>20.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-04-02</td>\n",
       "      <td>-10.880</td>\n",
       "      <td>-27.485</td>\n",
       "      <td>59.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-05-02</td>\n",
       "      <td>-7.550</td>\n",
       "      <td>-50.455</td>\n",
       "      <td>9.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BAB</td>\n",
       "      <td>47.98</td>\n",
       "      <td>-55.82</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1997-06-02</td>\n",
       "      <td>-5.835</td>\n",
       "      <td>-76.480</td>\n",
       "      <td>-29.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>3265</td>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>3266</td>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-04-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>3267</td>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>3268</td>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-06-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>3269</td>\n",
       "      <td>HAL</td>\n",
       "      <td>68.47</td>\n",
       "      <td>-81.15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-07-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3249 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index Station    Lat   Long    Alt       Date  O18Avg   H2avg     dex\n",
       "0         0     BAB  47.98 -55.82  190.0 1997-02-02 -10.520 -50.700  33.460\n",
       "1         1     BAB  47.98 -55.82  190.0 1997-03-02  -8.605 -48.040  20.800\n",
       "2         2     BAB  47.98 -55.82  190.0 1997-04-02 -10.880 -27.485  59.555\n",
       "3         3     BAB  47.98 -55.82  190.0 1997-05-02  -7.550 -50.455   9.945\n",
       "4         4     BAB  47.98 -55.82  190.0 1997-06-02  -5.835 -76.480 -29.800\n",
       "...     ...     ...    ...    ...    ...        ...     ...     ...     ...\n",
       "3244   3265     HAL  68.47 -81.15    8.0 2007-03-02     NaN     NaN     NaN\n",
       "3245   3266     HAL  68.47 -81.15    8.0 2007-04-02     NaN     NaN     NaN\n",
       "3246   3267     HAL  68.47 -81.15    8.0 2007-05-02     NaN     NaN     NaN\n",
       "3247   3268     HAL  68.47 -81.15    8.0 2007-06-02     NaN     NaN     NaN\n",
       "3248   3269     HAL  68.47 -81.15    8.0 2007-07-02     NaN     NaN     NaN\n",
       "\n",
       "[3249 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the date column to datetime format\n",
    "cnip[\"Date\"] = pd.to_datetime(cnip[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Filling in empty strings with NaN\n",
    "cnip = cnip.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Removing unnecessary columns\n",
    "cnip = cnip.drop([\"Month\", \"O18(1)\", \"O18(2)\", \"H2(1)\", \"H2(2)\", \"Prec(1)\", \"Prec(2)\", \"Prec(3)\", \"Temp\"], axis=1)\n",
    "\n",
    "# Removing rows in the Date column with NaT values\n",
    "cnip = cnip[cnip.Date.isnull() == False].reset_index()\n",
    "cnip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the CNIP dates to datetime objects with no time\n",
    "cnip[\"Date\"] = pd.to_datetime(cnip[\"Date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HydroGFD data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaxgr\\AppData\\Local\\Temp\\ipykernel_14504\\3512970601.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  precip = pd.concat([precip, df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished extracting data from 19600101-19641231\n",
      "Finished extracting data from 19650101-19691231\n",
      "Finished extracting data from 19700101-19741231\n",
      "Finished extracting data from 19750101-19791231\n",
      "Finished extracting data from 19800101-19841231\n",
      "Finished extracting data from 19850101-19891231\n",
      "Finished extracting data from 19900101-19941231\n",
      "Finished extracting data from 19950101-19991231\n",
      "Finished extracting data from 20000101-20041231\n",
      "Finished extracting data from 20050101-20051231\n",
      "Finished extracting data from 20060101-20101231\n"
     ]
    }
   ],
   "source": [
    "# All the precipitation file starts with a \"prAdjust\" and ends with a \".nc\"\n",
    "path = \"HydroGFD/prAdjust*\"\n",
    "precipFiles = glob.glob(path) #Creates a list of all the precipitation flux files relative paths\n",
    "\n",
    "# Loop through each precipitation file and extract the data which should only be separated by time\n",
    "# and store them in a single dataframe\n",
    "precip = pd.DataFrame(columns=[\"Station\",\"Lat\", \"Long\", \"Time\", \"Precipitation\"])\n",
    "\n",
    "# Loop through each file and pull out the data at each time step for every lat and lon coordinate we have in the CNIP dataset that is stored in the stationCoords dictionary\n",
    "for file in precipFiles:\n",
    "    ncid = nc.Dataset(file, \"r\")\n",
    "\n",
    "    #Pull out the time data and coordiante data\n",
    "    time = ncid.variables[\"time\"][:].filled(np.nan)\n",
    "    lat = ncid.variables[\"lat\"][:].filled(np.nan)\n",
    "    lon = ncid.variables[\"lon\"][:].filled(np.nan)\n",
    "\n",
    "    for stat, coords in stationCoords.items():\n",
    "        latIndex = (np.abs(lat - coords[0])).argmin()\n",
    "        lonIndex = (np.abs(lon - coords[1])).argmin()\n",
    "\n",
    "        # Pull out the precipitation data at each time step\n",
    "        precipData = ncid.variables[\"prAdjust\"][:, latIndex, lonIndex].filled(0) #Filling with 0 is an assumption that if there is no data, then there is no precipitation\n",
    "        \n",
    "        # Place the lat, lon, time, and precipitation data into a dataframe\n",
    "        df = pd.DataFrame({\"Station\": stat, \"Lat\": coords[0], \"Long\": coords[1], \"Time\": time, \"Precipitation\": precipData})\n",
    "        precip = pd.concat([precip, df], ignore_index=True)\n",
    "    print(\"Finished extracting data from \" + file[-20:-3])\n",
    "    ncid.close()\n",
    "\n",
    "# Convert the time data to datetime format\n",
    "precip[\"Time\"] = precip[\"Time\"].apply(lambda x: datetime(1850, 1, 1) + timedelta(days=x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaxgr\\AppData\\Local\\Temp\\ipykernel_14504\\808939274.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  temperature = pd.concat([temperature, df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished extracting data from 19600101-19641231\n",
      "Finished extracting data from 19650101-19691231\n",
      "Finished extracting data from 19700101-19741231\n",
      "Finished extracting data from 19750101-19791231\n",
      "Finished extracting data from 19800101-19841231\n",
      "Finished extracting data from 19850101-19891231\n",
      "Finished extracting data from 19900101-19941231\n",
      "Finished extracting data from 19950101-19991231\n",
      "Finished extracting data from 20000101-20041231\n",
      "Finished extracting data from 20050101-20051231\n",
      "Finished extracting data from 20060101-20101231\n"
     ]
    }
   ],
   "source": [
    "# All the temperature files starts with a \"tasAdjust\" and ends with a \".nc\"\n",
    "path = \"HydroGFD/tasAdjust*\"\n",
    "tempFiles = glob.glob(path) #Creates a list of all the temperature flux files relative paths\n",
    "\n",
    "# Loop through each temperature file and extract the data which should only be separated by time\n",
    "# and store them in a single dataframe\n",
    "temperature = pd.DataFrame(columns=[\"Station\",\"Lat\", \"Long\", \"Time\", \"Temperature\"])\n",
    "\n",
    "# Loop through each file and pull out the data at each time step for every lat and lon coordinate we have in the CNIP dataset that is stored in the stationCoords dictionary\n",
    "for file in tempFiles:\n",
    "    ncid = nc.Dataset(file, \"r\")\n",
    "\n",
    "    #Pull out the time data and coordiante data\n",
    "    time = ncid.variables[\"time\"][:].filled(np.nan)\n",
    "    lat = ncid.variables[\"lat\"][:].filled(np.nan)\n",
    "    lon = ncid.variables[\"lon\"][:].filled(np.nan)\n",
    "\n",
    "    for stat, coords in stationCoords.items():\n",
    "        latIndex = (np.abs(lat - coords[0])).argmin()\n",
    "        lonIndex = (np.abs(lon - coords[1])).argmin()\n",
    "\n",
    "        # Pull out the temperature data at each time step\n",
    "        tempData = ncid.variables[\"tasAdjust\"][:, latIndex, lonIndex].filled(np.nan) #Filling with nan, as we can't make an assumption about the temperature\n",
    "        \n",
    "        # Place the lat, lon, time, and temperature data into a dataframe\n",
    "        df = pd.DataFrame({\"Station\": stat, \"Lat\": coords[0], \"Long\": coords[1], \"Time\": time, \"Temperature\": tempData})\n",
    "        temperature = pd.concat([temperature, df], ignore_index=True)\n",
    "    print(\"Finished extracting data from \" + file[-20:-3])\n",
    "    ncid.close()\n",
    "\n",
    "# Convert the time data to datetime format\n",
    "temperature[\"Time\"] = temperature[\"Time\"].apply(lambda x: datetime(1850, 1, 1) + timedelta(days=x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HydroGFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the precipitation and temperature dataframes\n",
    "hydroGFD = pd.merge(precip, temperature, on=[\"Station\", \"Lat\", \"Long\", \"Time\"], how=\"outer\")\n",
    "\n",
    "# Keep only the needed columns of the dataframe: station, lat, long, time, precipitation, temperature\n",
    "# removing the index columns\n",
    "hydroGFD = hydroGFD[[\"Station\", \"Lat\", \"Long\", \"Time\", \"Precipitation\", \"Temperature\"]]\n",
    "\n",
    "# Renaming some columns to include units\n",
    "hydroGFD = hydroGFD.rename(columns={\n",
    "    \"Precipitation\": \"Precipitation (kg/m^2/s)\", \n",
    "    \"Temperature\": \"Temperature (K)\",\n",
    "    \"Time\": \"Date\"})\n",
    "\n",
    "hydroGFD = hydroGFD.sort_values([\"Date\"])\n",
    "\n",
    "# Finally saving this data as a CSV file just in case\n",
    "hydroGFD.to_csv(r\"hydroGFD.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make hydroGFD dates to datetime objects from strings\n",
    "hydroGFD[\"Date\"] = pd.to_datetime(hydroGFD[\"Date\"], format=\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I will pull out all the dates in CNIP and HydroGFD\n",
    "cnipDates = cnip[\"Date\"].unique()\n",
    "hydroGFDDates = hydroGFD[\"Date\"].unique()\n",
    "\n",
    "# Find the dates that are in both CNIP and HydroGFD\n",
    "commonDates = np.intersect1d(cnipDates, hydroGFDDates)\n",
    "\n",
    "# Remove the rows in the CNIP dataset that are not in the HydroGFD dataset and vice versa\n",
    "cnip = cnip[cnip.Date.isin(hydroGFD.Date)].reset_index()\n",
    "hydroGFD = hydroGFD[hydroGFD.Date.isin(cnip.Date)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the CNIP and HydroGFD dataframes so I don't have to rerun the code above\n",
    "cnipCopy = cnip.copy()\n",
    "hydroGFDCopy = hydroGFD.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the copies of the CNIP and HydroGFD dataframes. \n",
    "# This will allow me to compare the data between the two datasets\n",
    "cnipCopy = cnipCopy.drop([\"index\"], axis=1)\n",
    "hydroGFDCopy = hydroGFDCopy.drop([\"index\"], axis=1)\n",
    "\n",
    "# Merge the CNIP and HydroGFD dataframes\n",
    "merged = pd.merge(cnipCopy, hydroGFDCopy, on=[\"Station\", \"Lat\", \"Long\", \"Date\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.sort_values([\"Date\"]).reset_index()\n",
    "merged = merged.drop([\"index\", \"level_0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Station</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Date</th>\n",
       "      <th>O18Avg</th>\n",
       "      <th>H2avg</th>\n",
       "      <th>dex</th>\n",
       "      <th>Precipitation (kg/m^2/s)</th>\n",
       "      <th>Temperature (K)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2179</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1970-02-15</td>\n",
       "      <td>-17.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>266.265289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2212</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1970-03-15</td>\n",
       "      <td>-16.790000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>274.185883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2230</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1970-04-15</td>\n",
       "      <td>-12.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>275.309753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2242</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1970-05-15</td>\n",
       "      <td>-7.960000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>285.693298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2267</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1970-06-15</td>\n",
       "      <td>-6.840000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>285.053406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>12023</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>-6.524852</td>\n",
       "      <td>-43.06</td>\n",
       "      <td>9.138815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.785278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>12040</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2007-09-02</td>\n",
       "      <td>-10.019821</td>\n",
       "      <td>-68.22</td>\n",
       "      <td>11.938571</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>295.114288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>12058</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2007-10-02</td>\n",
       "      <td>-6.432879</td>\n",
       "      <td>-37.64</td>\n",
       "      <td>13.823032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>288.457428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>12076</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2007-11-02</td>\n",
       "      <td>-10.933000</td>\n",
       "      <td>-74.53</td>\n",
       "      <td>12.934000</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>278.316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>12093</td>\n",
       "      <td>OTT</td>\n",
       "      <td>45.32</td>\n",
       "      <td>-75.67</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2007-12-02</td>\n",
       "      <td>-17.170000</td>\n",
       "      <td>-129.64</td>\n",
       "      <td>7.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>264.792389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2574 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index Station    Lat   Long    Alt       Date     O18Avg   H2avg  \\\n",
       "0      2179     OTT  45.32 -75.67  114.0 1970-02-15 -17.300000     NaN   \n",
       "1      2212     OTT  45.32 -75.67  114.0 1970-03-15 -16.790000     NaN   \n",
       "2      2230     OTT  45.32 -75.67  114.0 1970-04-15 -12.570000     NaN   \n",
       "3      2242     OTT  45.32 -75.67  114.0 1970-05-15  -7.960000     NaN   \n",
       "4      2267     OTT  45.32 -75.67  114.0 1970-06-15  -6.840000     NaN   \n",
       "...     ...     ...    ...    ...    ...        ...        ...     ...   \n",
       "2569  12023     OTT  45.32 -75.67  114.0 2007-08-02  -6.524852  -43.06   \n",
       "2570  12040     OTT  45.32 -75.67  114.0 2007-09-02 -10.019821  -68.22   \n",
       "2571  12058     OTT  45.32 -75.67  114.0 2007-10-02  -6.432879  -37.64   \n",
       "2572  12076     OTT  45.32 -75.67  114.0 2007-11-02 -10.933000  -74.53   \n",
       "2573  12093     OTT  45.32 -75.67  114.0 2007-12-02 -17.170000 -129.64   \n",
       "\n",
       "            dex  Precipitation (kg/m^2/s)  Temperature (K)  \n",
       "0           NaN                  0.000146       266.265289  \n",
       "1           NaN                  0.000000       274.185883  \n",
       "2           NaN                  0.000000       275.309753  \n",
       "3           NaN                  0.000000       285.693298  \n",
       "4           NaN                  0.000000       285.053406  \n",
       "...         ...                       ...              ...  \n",
       "2569   9.138815                  0.000000       290.785278  \n",
       "2570  11.938571                  0.000042       295.114288  \n",
       "2571  13.823032                  0.000000       288.457428  \n",
       "2572  12.934000                  0.000036       278.316406  \n",
       "2573   7.720000                  0.000000       264.792389  \n",
       "\n",
       "[2574 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all rows that have Nan values in the O18Avg\n",
    "merged = merged[merged[\"O18Avg\"].isnull() == False].reset_index()\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the merged dataframe to a CSV file\n",
    "merged.to_csv(r\"merged.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
